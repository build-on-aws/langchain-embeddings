# ğŸ““ Jupyter Notebooks - Interactive Learning Path

<div align="center">


### ğŸ¯ **Master Multimodal AI Through Hands-On Tutorials**

[![Notebooks](https://img.shields.io/badge/7-Interactive_Notebooks-blue?style=for-the-badge&logo=jupyter)](.)
[![Difficulty](https://img.shields.io/badge/Beginner_to_Expert-All_Levels-green?style=for-the-badge)](.)
[![Time](https://img.shields.io/badge/30min_to_2hrs-Per_Notebook-orange?style=for-the-badge&logo=clock)](.)

</div>

Learn multimodal AI through practical tutorials that demonstrate text, image, and video processing with Amazon Bedrock and AWS services.

---

## ğŸ“š Complete Learning Sequence

| ğŸ““ Notebook | ğŸ¯ Focus & Key Learning | â±ï¸ Time | ğŸ“Š Level | ğŸ–¼ï¸ Diagram |
|-------------|------------------------|----------|----------|------------|
| **01 - [Semantic Search with LangChain, Amazon Titan Embeddings, and FAISS](01_build_pdf_vector_db.ipynb)** | Text embeddings and PDF processing - Document chunking, embeddings generation, FAISS vector store operations | 30 min | ![Beginner](https://img.shields.io/badge/-Beginner-brightgreen) |  ![Video Understanding](data/build_pdf_vector_db.jpg)|
| **02 - [Building a Multimodal Image Search App with Titan Embeddings](02_build_images_vector_db.ipynb)** | Visual search capabilities - Image embeddings, multimodal search, natural language image queries | 45 min | ![Intermediate](https://img.shields.io/badge/-Intermediate-yellow) | ![Video Understanding](data/build_images_vector_db.jpg) |
| **03 - [Supercharging Vector Similarity Search with Amazon Aurora and pgvector](03_build_pgvector_db.ipynb)** | Production database setup - PostgreSQL vector operations, pgvector extension, scalable similarity search | 60 min | ![Intermediate](https://img.shields.io/badge/-Intermediate-yellow) | |
| **04 - [Video Understanding](04_video_understanding.ipynb)** | Video content analysis - Nova models for video processing, content extraction, video understanding workflows | 45 min | ![Advanced](https://img.shields.io/badge/-Advanced-red) | ![Video Understanding](data/video_understanding.png) |
| **05 - [Video and Audio Content Analysis with Amazon Bedrock](05_create_audio_video_embeddings.ipynb)** | Audio processing workflows - Transcription, audio embeddings, multimedia content analysis | 40 min | ![Advanced](https://img.shields.io/badge/-Advanced-red) | ![Video Analysis](data/diagram_video.png) |
| **06 - [Building Agentic Video RAG with Strands Agents - Local](06_video_embeddings_with_strands_enhanced.ipynb)** | AI agents for video analysis - Local agent implementation, memory-enhanced agents, persistent context storage | 90 min | ![Expert](https://img.shields.io/badge/-Expert-purple) | ![Local Agent](data/agent_videoembedding_local_memory.png) |
| **07 - [Building Agentic Video RAG with Strands Agents - Cloud](07_video_embeddings_container_with_strands_agents.ipynb)** | Production agent deployment - Cloud-based agent architecture, ECS deployment, scalable agent workflows | 120 min | ![Expert](https://img.shields.io/badge/-Expert-purple) | ![Cloud Agent](data/agent_videoembedding_cloud_memory.png) |

---

## ğŸ”§ AWS Services You'll Use

| ğŸ”§ Service | ğŸ¯ Purpose | âš¡ Key Capabilities |
|-------------|------------|---------------------|
| **[Amazon Bedrock](https://aws.amazon.com/bedrock/?trk=4f1e9f0e-7b21-4369-8925-61f67341d27c&sc_channel=el)** | AI model access | Titan Embeddings, Nova models for multimodal processing |
| **[Amazon Aurora PostgreSQL](https://aws.amazon.com/rds/aurora/?trk=4f1e9f0e-7b21-4369-8925-61f67341d27c&sc_channel=el)** | Vector database | pgvector extension for similarity search operations |
| **[Amazon S3](https://aws.amazon.com/s3/?trk=4f1e9f0e-7b21-4369-8925-61f67341d27c&sc_channel=el)** | Object storage | Document, image, and video content storage |
| **[Amazon Transcribe](https://aws.amazon.com/transcribe/?trk=4f1e9f0e-7b21-4369-8925-61f67341d27c&sc_channel=el)** | Speech-to-text | Audio content extraction from video files |

---

## ğŸ› ï¸ Prerequisites & Setup

**ğŸ“‹ Before You Begin:**
- âœ… AWS Account with Amazon Bedrock access enabled
- âœ… Python 3.8+ installed locally
- âœ… AWS CLI configured with appropriate permissions
- âœ… Jupyter Notebook or JupyterLab installed

**ğŸ“¦ Required Python Packages:**
```bash
# All requirements are in requirements.txt
# Install after creating virtual environment (see Quick Start Guide)
```

**ğŸ”‘ AWS Credentials Setup:**
Follow the [AWS credentials configuration guide](https://docs.aws.amazon.com/braket/latest/developerguide/braket-using-boto3.html?trk=4f1e9f0e-7b21-4369-8925-61f67341d27c&sc_channel=el) to configure your environment.

---

## ğŸš€ Quick Start Guide

### 1ï¸âƒ£ **Clone & Setup Environment** (3 minutes)
```bash
git clone https://github.com/build-on-aws/langchain-embeddings.git
cd langchain-embeddings/notebooks

# Create virtual environment
python -m venv venv

# Activate environment (macOS/Linux)
source venv/bin/activate
# Or on Windows
# venv\Scripts\activate

# Install requirements
pip install -r requirements.txt
```

### 2ï¸âƒ£ **Start Learning** (30 seconds)
```bash
jupyter notebook 01_build_pdf_vector_db.ipynb
```

### 3ï¸âƒ£ **Follow the Path** 
Complete notebooks 01-07 in sequence for the best learning experience.

---

## ğŸ’° Estimated Costs

| ğŸ’° Notebook Range | ğŸ”§ AWS Services Used | 
|-------------------|---------------------|
| **01-02** | Bedrock, S3 | 
| **03** | Aurora PostgreSQL | 
| **04-05** | Bedrock, Transcribe, S3 |
| **06-07** | Full stack | 

> ğŸ’¡ **Pro Tip:** Use AWS Free Tier when possible and monitor costs through [AWS Cost Explorer](https://aws.amazon.com/aws-cost-management/aws-cost-explorer/?trk=4f1e9f0e-7b21-4369-8925-61f67341d27c&sc_channel=el).

---

## ğŸ’¡ Learning Tips for Success

| ğŸ¯ Tip | ğŸ“ Description |
|---------|----------------|
| **ğŸ“š Start Sequential** | Follow the numbered order for best learning experience |
| **ğŸ”¬ Experiment** | Modify code examples to understand concepts better |
| **ğŸ’° Monitor Costs** | Check AWS usage, especially for Bedrock API calls |
| **ğŸ’¾ Save Work** | Export important results before closing notebooks |

---

## ğŸ”— Additional Learning Resources

- ğŸ“– [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/?trk=4f1e9f0e-7b21-4369-8925-61f67341d27c&sc_channel=el)
- ğŸ¦œ [LangChain Python Documentation](https://python.langchain.com/)
- ğŸ” [FAISS Documentation](https://faiss.ai/)
- ğŸ—„ï¸ [pgvector Documentation](https://github.com/pgvector/pgvector)

---

<div align="center">

## ğŸ  Ready to Deploy? 

**Completed the notebooks? Take your learning to production!**

[![Back to Main](https://img.shields.io/badge/ğŸ _Back_to_Main_Repository-blue?style=for-the-badge&logo=github)](../README.md)
[![Deploy Aurora DB](https://img.shields.io/badge/ğŸ—„ï¸_Deploy_Aurora_DB-yellow?style=for-the-badge&logo=amazon-aws)](../create-aurora-pgvector/)
[![Build Serverless APIs](https://img.shields.io/badge/âš¡_Build_Serverless_APIs-orange?style=for-the-badge&logo=aws-lambda)](../serveless-embeddings/)
[![Scale with Containers](https://img.shields.io/badge/ğŸ¥_Scale_with_Containers-red?style=for-the-badge&logo=docker)](../container-video-embeddings/)

### â­ **Found this helpful? Star the repository!** â­

[![Star History](https://api.star-history.com/svg?repos=build-on-aws/langchain-embeddings&type=Date)](https://star-history.com/#build-on-aws/langchain-embeddings&Date)

**ğŸ¯ [Explore More AWS Learning Resources](https://github.com/build-on-aws) â€¢ ğŸš€ [Join the AWS Community](https://builder.aws.com/)**

</div>

---

## ğŸ“„ License

This library is licensed under the MIT-0 License. See the [LICENSE](../LICENSE) file for details.
